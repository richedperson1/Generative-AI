{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AFqfobiO-nY"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPITdZmqPAEa",
        "outputId": "66fd5025-3cae-4796-ce0f-4e082c3c8bb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.0/990.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m373.5/373.5 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.1/519.1 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.9/328.9 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-aiplatform 1.59.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-bigtable 2.24.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.27.2 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.2 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.27.2 which is incompatible.\n",
            "langchain-weaviate 0.0.2 requires numpy<2.0.0,>=1.26.2, but you have numpy 1.24.4 which is incompatible.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m868.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain_community\n",
        "!pip install --quiet pypdf\n",
        "# !pip install --quiet langchain_weaviate\n",
        "# !pip install --quiet rank_bm25\n",
        "# !pip install --quiet -U sentence-transformers\n",
        "!pip install --quiet numpy==1.24.4\n",
        "!pip install --quiet bitsandbytes\n",
        "!pip install --quiet accelerate\n",
        "!pip install --quiet transformers datasets accelerate nvidia-ml-py3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRrM0EJoPOrT"
      },
      "source": [
        "## Library importing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uaOEWN8cPQ9-"
      },
      "outputs": [],
      "source": [
        "import weaviate\n",
        "from langchain.retrievers.weaviate_hybrid_search import WeaviateHybridSearchRetriever\n",
        "from sentence_transformers import CrossEncoder\n",
        "import cohere\n",
        "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "# from langchain_cohere import CohereRerank\n",
        "from langchain_community.llms import Cohere"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTJQgB0GPI3f"
      },
      "source": [
        "##  DB connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x6VmnuU1PLLx"
      },
      "outputs": [],
      "source": [
        "\n",
        "WEAVIATE_URL=\"https://7nqntzuktg2lbtg7c2kieg.c0.asia-southeast1.gcp.weaviate.cloud\"\n",
        "WEAVIATE_API_KEY=\"AteUZy389qPSWJnYPYd7xSwjL3y8NtkBsYRg\"\n",
        "HF_TOKEN = \"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\"\n",
        "client = weaviate.Client(\n",
        "    url=WEAVIATE_URL, auth_client_secret=weaviate.AuthApiKey(WEAVIATE_API_KEY),\n",
        "    additional_headers={\n",
        "         \"X-HuggingFace-Api-Key\": HF_TOKEN\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZHGi0G2PWh4"
      },
      "source": [
        "## DB retrival"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WQNCp9XqPYHA"
      },
      "outputs": [],
      "source": [
        "retriever = WeaviateHybridSearchRetriever(\n",
        "    alpha = 0.5,               # defaults to 0.5, which is equal weighting between keyword and semantic search\n",
        "    client = client,           # keyword arguments to pass to the Weaviate client\n",
        "    index_name = \"RAG1\",  # The name of the index to use\n",
        "    text_key = \"content\",         # The name of the text key to use\n",
        "    attributes = [], # The attributes to return in the results\n",
        "    # create_schema_if_missing=True,\n",
        "    # max_results=10,\n",
        "    # k= 10\n",
        "    # top_k=10,\n",
        "    # alpha=0.5,\n",
        "    # semantic_search_kwargs={\n",
        "        # \"limit\": 10,\n",
        "    # }\n",
        "    k= 10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i1JDzxZBPFzM"
      },
      "outputs": [],
      "source": [
        "query = \"samsung family mall benifits for employee\"\n",
        "docs = retriever.invoke(query,score=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMtWltADnXNW",
        "outputId": "7e23fcf3-8705-49ff-9afa-db63f03775d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': None,\n",
              " 'metadata': {'_additional': {'explainScore': '\\nHybrid (Result Set keyword,bm25) Document 0147a06d-28bd-4987-ab9c-6d0db4f143e2: original score 2.363366, normalized score: 0.5 - \\nHybrid (Result Set vector,hybridVector) Document 0147a06d-28bd-4987-ab9c-6d0db4f143e2: original score 0.5726322, normalized score: 0.4551769',\n",
              "   'score': '0.9551769'}},\n",
              " 'page_content': 'SAMSUNG FAMILY MALL \\n \\n1. What is Samsung Family Mall? \\nSamsung Family Mall is an online platform that gives exclusive discounts on select Samsung products to all \\nemployees of Samsung and its subsidiaries based in India – including HARMAN. This mall is open 24/7 for our \\nemployees . Please see ‘ Flash Sales’  section below before making a purchase. \\n \\n2. How do I access the Family Mall? \\nGo to https://shop.samsung.com/in/employee/ and log in with your HARMAN email ID.  \\nYou will receive an OTP from Samsung Shop on your HARMAN email ID. Enter the OTP and log in the portal \\nto make your purchase. \\n \\n3. I cannot open this site, what should I do? \\nIf the site does not open on your machine, please clear your browser history and try again. This website \\nworks best on Google Chrome. If you are still unable to log in, check with your DIG ITAL team. \\n \\n4. Who can I contact for delivery status or any other query?',\n",
              " 'type': 'Document'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0].__dict__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8ZPGvlAQZRq"
      },
      "source": [
        "## Cross Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgP6N2wjQa2Z"
      },
      "outputs": [],
      "source": [
        "cross_encoder_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uWNbm0iReNA"
      },
      "outputs": [],
      "source": [
        "scores = cross_encoder_model.predict([('A man is eating pizza', 'A man eats something')])\n",
        "# label_mapping = ['contradiction', 'entailment', 'neutral']\n",
        "# labels = [label_mapping[score_max] for score_max in scores.argmax(axis=1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQcYRMiHR1i1",
        "outputId": "b3540d8c-60fe-42fc-8d7b-b8b59465aad0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.3051626], dtype=float32)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI-je0NIS7Rj"
      },
      "source": [
        "## Cohere client set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8bPjckgUM41"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"COHERE_API_KEY\"]  = \"nbDqU1hTVxWmXGbLYI6OnYhp4Cx40MZ5hOmO5oKX\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vylNzw2S6Y_",
        "outputId": "6c6a4400-cbae-4947-cd77-1528493172d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<cohere.client.Client at 0x7fec01bc6e60>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cohere_rerank = cohere.Client(\"nbDqU1hTVxWmXGbLYI6OnYhp4Cx40MZ5hOmO5oKX\")\n",
        "\n",
        "cohere_rerank"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ouzWRLCTDCe"
      },
      "outputs": [],
      "source": [
        "compressor = CohereRerank(model=\"rerank-english-v3.0\",top_n = 5)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=retriever\n",
        ")\n",
        "\n",
        "# compressed_docs = compression_retriever.invoke(\n",
        "#     \"What did the president say about Ketanji Jackson Brown\"\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzFYuajuUUOe"
      },
      "outputs": [],
      "source": [
        "result_cohere = compression_retriever.invoke(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-HeOgQmVQpc"
      },
      "outputs": [],
      "source": [
        "rerank_response_results_itemresult = []\n",
        "for data in result_cohere:\n",
        "    # print(data.page_content)\n",
        "    local_weight = cross_encoder_model.predict([query,data.page_content])\n",
        "    rerank_response_results_itemresult.append({\n",
        "        \"page_content\": data.page_content,\n",
        "        \"score\": local_weight\n",
        "    })\n",
        "# print(total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LMIXkiOUcFf"
      },
      "outputs": [],
      "source": [
        "rerank_response_results_itemresult"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
