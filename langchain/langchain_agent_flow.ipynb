{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM model declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY = \"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\"\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "llm = ChatGroq(temperature=0, model_name=\"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply_two_number(a: int,b:int) -> int:\n",
    "    \"\"\"To multiply two given number such as a and b and give the result\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "@tool\n",
    "def random_numer_generator() -> int:\n",
    "    \"\"\"Generating random number from 0 to 5\"\"\"\n",
    "    return random.randint(0,5)\n",
    "\n",
    "\n",
    "tool_list = [multiply_two_number, random_numer_generator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_5eqb', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply_two_number'}, 'type': 'function'}, {'id': 'call_fw5m', 'function': {'arguments': '{}', 'name': 'random_numer_generator'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 1013, 'total_tokens': 1126, 'completion_time': 0.150666667, 'prompt_time': 0.32230261, 'queue_time': None, 'total_time': 0.472969277}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f66ccb39ec', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bfd442b4-d536-4ec6-8dce-2d9fdbb428dc-0', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 2, 'b': 3}, 'id': 'call_5eqb', 'type': 'tool_call'}, {'name': 'random_numer_generator', 'args': {}, 'id': 'call_fw5m', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1013, 'output_tokens': 113, 'total_tokens': 1126})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_tools.invoke(\"what is 2 * 3? can you generate some number from 1 to 5 \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def fake_weather_api(city: str) -> str:\n",
    "    \"\"\"Check the weather in a specified city.\"\"\"\n",
    "    return \"Sunny, 22Â°C\"\n",
    "\n",
    "@tool\n",
    "def outdoor_seating_availability(city: str) -> str:\n",
    "    \"\"\"Check if outdoor seating is available at a specified restaurant in a given city.\"\"\"\n",
    "    return \"Outdoor seating is available.\"\n",
    "\n",
    "\n",
    "tools = [fake_weather_api, outdoor_seating_availability]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_zcsd', 'function': {'arguments': '{\"city\":\"munich\"}', 'name': 'fake_weather_api'}, 'type': 'function'}, {'id': 'call_fmhw', 'function': {'arguments': '{\"city\":\"munich\"}', 'name': 'outdoor_seating_availability'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 1026, 'total_tokens': 1146, 'completion_time': 0.16, 'prompt_time': 0.300571946, 'queue_time': None, 'total_time': 0.46057194599999995}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_9cb648b966', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e951f795-a33c-4c94-bbbc-d8fdea31ea25-0', tool_calls=[{'name': 'fake_weather_api', 'args': {'city': 'munich'}, 'id': 'call_zcsd', 'type': 'tool_call'}, {'name': 'outdoor_seating_availability', 'args': {'city': 'munich'}, 'id': 'call_fmhw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1026, 'output_tokens': 120, 'total_tokens': 1146})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "result = llm_with_tools.invoke(\"How will the weather be in munich today? I would like to eat outside if possible\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\set up\\Anacoda\\installation\\envs\\langchain-env\\Lib\\site-packages\\langchain\\hub.py:86: DeprecationWarning: The `langchainhub sdk` is deprecated.\n",
      "Please use the `langsmith sdk` instead:\n",
      "  pip install langsmith\n",
      "Use the `pull_prompt` method.\n",
      "  res_dict = client.pull_repo(owner_repo_commit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "agent = create_tool_calling_agent(llm, tool_list, prompt)\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\set up\\Anacoda\\installation\\envs\\langchain-env\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> {'actions': [ToolAgentAction(tool='multiply_two_number', tool_input={'a': 2, 'b': 3}, log=\"\\nInvoking: `multiply_two_number` with `{'a': 2, 'b': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_2023', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply_two_number'}, 'type': 'function'}, {'id': 'call_j4gh', 'function': {'arguments': '{}', 'name': 'random_numer_generator'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-49fc4524-ee78-4cec-ac77-89570db07f5c', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 2, 'b': 3}, 'id': 'call_2023', 'type': 'tool_call'}, {'name': 'random_numer_generator', 'args': {}, 'id': 'call_j4gh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1022, 'output_tokens': 113, 'total_tokens': 1135}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":2,\"b\":3}', 'id': 'call_2023', 'index': None, 'type': 'tool_call_chunk'}, {'name': 'random_numer_generator', 'args': '{}', 'id': 'call_j4gh', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_2023')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_2023', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply_two_number'}, 'type': 'function'}, {'id': 'call_j4gh', 'function': {'arguments': '{}', 'name': 'random_numer_generator'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-49fc4524-ee78-4cec-ac77-89570db07f5c', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 2, 'b': 3}, 'id': 'call_2023', 'type': 'tool_call'}, {'name': 'random_numer_generator', 'args': {}, 'id': 'call_j4gh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1022, 'output_tokens': 113, 'total_tokens': 1135}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":2,\"b\":3}', 'id': 'call_2023', 'index': None, 'type': 'tool_call_chunk'}, {'name': 'random_numer_generator', 'args': '{}', 'id': 'call_j4gh', 'index': None, 'type': 'tool_call_chunk'}])]}\n",
      "==> {'actions': [ToolAgentAction(tool='random_numer_generator', tool_input={}, log='\\nInvoking: `random_numer_generator` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_2023', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply_two_number'}, 'type': 'function'}, {'id': 'call_j4gh', 'function': {'arguments': '{}', 'name': 'random_numer_generator'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-49fc4524-ee78-4cec-ac77-89570db07f5c', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 2, 'b': 3}, 'id': 'call_2023', 'type': 'tool_call'}, {'name': 'random_numer_generator', 'args': {}, 'id': 'call_j4gh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1022, 'output_tokens': 113, 'total_tokens': 1135}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":2,\"b\":3}', 'id': 'call_2023', 'index': None, 'type': 'tool_call_chunk'}, {'name': 'random_numer_generator', 'args': '{}', 'id': 'call_j4gh', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_j4gh')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_2023', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply_two_number'}, 'type': 'function'}, {'id': 'call_j4gh', 'function': {'arguments': '{}', 'name': 'random_numer_generator'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-49fc4524-ee78-4cec-ac77-89570db07f5c', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 2, 'b': 3}, 'id': 'call_2023', 'type': 'tool_call'}, {'name': 'random_numer_generator', 'args': {}, 'id': 'call_j4gh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1022, 'output_tokens': 113, 'total_tokens': 1135}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":2,\"b\":3}', 'id': 'call_2023', 'index': None, 'type': 'tool_call_chunk'}, {'name': 'random_numer_generator', 'args': '{}', 'id': 'call_j4gh', 'index': None, 'type': 'tool_call_chunk'}])]}\n",
      "==> {'steps': [AgentStep(action=ToolAgentAction(tool='multiply_two_number', tool_input={'a': 2, 'b': 3}, log=\"\\nInvoking: `multiply_two_number` with `{'a': 2, 'b': 3}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_2023', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply_two_number'}, 'type': 'function'}, {'id': 'call_j4gh', 'function': {'arguments': '{}', 'name': 'random_numer_generator'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-49fc4524-ee78-4cec-ac77-89570db07f5c', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 2, 'b': 3}, 'id': 'call_2023', 'type': 'tool_call'}, {'name': 'random_numer_generator', 'args': {}, 'id': 'call_j4gh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1022, 'output_tokens': 113, 'total_tokens': 1135}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":2,\"b\":3}', 'id': 'call_2023', 'index': None, 'type': 'tool_call_chunk'}, {'name': 'random_numer_generator', 'args': '{}', 'id': 'call_j4gh', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_2023'), observation=6)], 'messages': [FunctionMessage(content='6', name='multiply_two_number')]}\n",
      "==> {'steps': [AgentStep(action=ToolAgentAction(tool='random_numer_generator', tool_input={}, log='\\nInvoking: `random_numer_generator` with `{}`\\n\\n\\n', message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_2023', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply_two_number'}, 'type': 'function'}, {'id': 'call_j4gh', 'function': {'arguments': '{}', 'name': 'random_numer_generator'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-49fc4524-ee78-4cec-ac77-89570db07f5c', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 2, 'b': 3}, 'id': 'call_2023', 'type': 'tool_call'}, {'name': 'random_numer_generator', 'args': {}, 'id': 'call_j4gh', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1022, 'output_tokens': 113, 'total_tokens': 1135}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":2,\"b\":3}', 'id': 'call_2023', 'index': None, 'type': 'tool_call_chunk'}, {'name': 'random_numer_generator', 'args': '{}', 'id': 'call_j4gh', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_j4gh'), observation=0)], 'messages': [FunctionMessage(content='0', name='random_numer_generator')]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\set up\\Anacoda\\installation\\envs\\langchain-env\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> {'actions': [ToolAgentAction(tool='multiply_two_number', tool_input={'a': 6, 'b': 0}, log=\"\\nInvoking: `multiply_two_number` with `{'a': 6, 'b': 0}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_89dw', 'function': {'arguments': '{\"a\":6,\"b\":0}', 'name': 'multiply_two_number'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cb1cf4b5-8dbf-4a81-a212-8a860bec36d4', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 6, 'b': 0}, 'id': 'call_89dw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1144, 'output_tokens': 41, 'total_tokens': 1185}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":6,\"b\":0}', 'id': 'call_89dw', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_89dw')], 'messages': [AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_89dw', 'function': {'arguments': '{\"a\":6,\"b\":0}', 'name': 'multiply_two_number'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cb1cf4b5-8dbf-4a81-a212-8a860bec36d4', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 6, 'b': 0}, 'id': 'call_89dw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1144, 'output_tokens': 41, 'total_tokens': 1185}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":6,\"b\":0}', 'id': 'call_89dw', 'index': None, 'type': 'tool_call_chunk'}])]}\n",
      "==> {'steps': [AgentStep(action=ToolAgentAction(tool='multiply_two_number', tool_input={'a': 6, 'b': 0}, log=\"\\nInvoking: `multiply_two_number` with `{'a': 6, 'b': 0}`\\n\\n\\n\", message_log=[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'id': 'call_89dw', 'function': {'arguments': '{\"a\":6,\"b\":0}', 'name': 'multiply_two_number'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cb1cf4b5-8dbf-4a81-a212-8a860bec36d4', tool_calls=[{'name': 'multiply_two_number', 'args': {'a': 6, 'b': 0}, 'id': 'call_89dw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1144, 'output_tokens': 41, 'total_tokens': 1185}, tool_call_chunks=[{'name': 'multiply_two_number', 'args': '{\"a\":6,\"b\":0}', 'id': 'call_89dw', 'index': None, 'type': 'tool_call_chunk'}])], tool_call_id='call_89dw'), observation=0)], 'messages': [FunctionMessage(content='0', name='multiply_two_number')]}\n",
      "==> {'output': 'The result of 2*3 is 6, and the random number generated was 0. Multiplying 6 and 0 results in 0.', 'messages': [AIMessage(content='The result of 2*3 is 6, and the random number generated was 0. Multiplying 6 and 0 results in 0.')]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\set up\\Anacoda\\installation\\envs\\langchain-env\\Lib\\site-packages\\pydantic\\main.py:1087: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.8/migration/\n",
      "  warnings.warn('The `dict` method is deprecated; use `model_dump` instead.', category=PydanticDeprecatedSince20)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
